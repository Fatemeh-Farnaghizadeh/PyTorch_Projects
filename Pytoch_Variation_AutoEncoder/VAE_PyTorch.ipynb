{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 2, 1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, 2, 1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, 3, 2, 1)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        self.fc1 = nn.Linear(256*4*4, 1024)\n",
    "        self.fc_mu = nn.Linear(1024, 20)\n",
    "        self.fc_sigma = nn.Linear(1024, 20)\n",
    "\n",
    "        self.fc2 = nn.Linear(20, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 256*4*4)\n",
    "\n",
    "        self.transpose1 = nn.ConvTranspose2d(256, 128, 3, 2, 1)\n",
    "        self.transpose2 = nn.ConvTranspose2d(128, 64, 4, 2, 1)\n",
    "        self.transpose3 = nn.ConvTranspose2d(64, 32, 4, 2, 1)\n",
    "        self.transpose4 = nn.ConvTranspose2d(32, 1, 3, 1, 1)\n",
    "\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.bn6 = nn.BatchNorm2d(64)\n",
    "        self.bn7 = nn.BatchNorm2d(32)\n",
    "\n",
    "    \n",
    "    def encoder(self, input):\n",
    "        x = torch.relu(self.bn1(self.conv1(input)))\n",
    "        x = torch.relu(self.bn2(self.conv2(x)))\n",
    "        x = torch.relu(self.bn3(self.conv3(x)))\n",
    "        x = torch.relu(self.bn4(self.conv4(x)))\n",
    "        \n",
    "\n",
    "        x = x.view(-1, 256*4*4)\n",
    "\n",
    "        x = self.fc1(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        sigma = self.fc_sigma(x)\n",
    "\n",
    "        return mu, sigma\n",
    "    \n",
    "\n",
    "    def reparameterize(self, mu, sigma):\n",
    "        eps = torch.randn_like(sigma)\n",
    "\n",
    "        return mu + eps * (torch.exp(0.5 * sigma))\n",
    "    \n",
    "    def decoder(self, z):\n",
    "\n",
    "        z = torch.relu(self.fc2(z))\n",
    "        z = torch.relu(self.fc3(z))\n",
    "\n",
    "        z = z.view(-1, 256, 4, 4)\n",
    "\n",
    "        z = torch.relu(self.bn5(self.transpose1(z)))\n",
    "        z = torch.relu(self.bn6(self.transpose2(z)))\n",
    "        z = torch.relu(self.bn7(self.transpose3(z)))\n",
    "\n",
    "        z = torch.sigmoid(self.transpose4(z))\n",
    "\n",
    "        return z\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, sigma = self.encoder(x)\n",
    "        z = self.reparameterize(mu, sigma)\n",
    "        decoded = self.decoder(z)\n",
    "\n",
    "        return mu, sigma, decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (fc_mu): Linear(in_features=1024, out_features=20, bias=True)\n",
       "  (fc_sigma): Linear(in_features=1024, out_features=20, bias=True)\n",
       "  (fc2): Linear(in_features=20, out_features=1024, bias=True)\n",
       "  (fc3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "  (transpose1): ConvTranspose2d(256, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (transpose2): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (transpose3): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (transpose4): ConvTranspose2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn7): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VAE().to(device)\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(recon_x, x, mu, sigma):\n",
    "    criterion = nn.BCELoss(reduction='sum')\n",
    "    recon_loss = criterion(recon_x, x)\n",
    "\n",
    "    kl_loss = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "\n",
    "    loss = recon_loss + kl_loss\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0 loss: 7281934.5\n",
      "epoch1 loss: 6360243.5\n",
      "epoch2 loss: 6179770.0\n",
      "epoch3 loss: 6070091.5\n",
      "epoch4 loss: 5993757.0\n",
      "epoch5 loss: 5935467.0\n",
      "epoch6 loss: 5890907.5\n",
      "epoch7 loss: 5855821.0\n",
      "epoch8 loss: 5823432.5\n",
      "epoch9 loss: 5800655.5\n",
      "epoch10 loss: 5776009.0\n",
      "epoch11 loss: 5757637.5\n",
      "epoch12 loss: 5740587.5\n",
      "epoch13 loss: 5723518.0\n",
      "epoch14 loss: 5709404.0\n",
      "epoch15 loss: 5695927.0\n",
      "epoch16 loss: 5681567.5\n",
      "epoch17 loss: 5672450.5\n",
      "epoch18 loss: 5659185.0\n",
      "epoch19 loss: 5651089.5\n",
      "epoch20 loss: 5642653.0\n",
      "epoch21 loss: 5631959.0\n",
      "epoch22 loss: 5623672.5\n",
      "epoch23 loss: 5615472.5\n",
      "epoch24 loss: 5605484.0\n",
      "epoch25 loss: 5602502.5\n",
      "epoch26 loss: 5595939.5\n",
      "epoch27 loss: 5587775.5\n",
      "epoch28 loss: 5579268.5\n",
      "epoch29 loss: 5575853.5\n",
      "epoch30 loss: 5567870.5\n",
      "epoch31 loss: 5566894.5\n",
      "epoch32 loss: 5558709.5\n",
      "epoch33 loss: 5550905.5\n",
      "epoch34 loss: 5548839.0\n",
      "epoch35 loss: 5544269.0\n",
      "epoch36 loss: 5537854.0\n",
      "epoch37 loss: 5533803.5\n",
      "epoch38 loss: 5530531.5\n",
      "epoch39 loss: 5521702.5\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for x, _ in train_loader:\n",
    "        x = x.to(device)\n",
    "        mu, sigma, x_reconst = model(x)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            loss = vae_loss(x_reconst, x, mu, sigma)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss += loss\n",
    "\n",
    "    print(f'epoch{epoch} loss: {epoch_loss}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu = torch.zeros(20)\n",
    "sigma = torch.ones(20)\n",
    "n_samples = 1\n",
    "latent_vars = torch.normal(mu, sigma.expand(n_samples, -1)).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    decoded_data = model.decoder(latent_vars)\n",
    "\n",
    "decoded_data_np = decoded_data.cpu().numpy().reshape(28, 28)\n",
    "plt.imshow(decoded_data_np, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = \"model.pth\"\n",
    "torch.save(model, FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
