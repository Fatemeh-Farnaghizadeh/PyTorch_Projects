{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.FashionMNIST(root='.', download=True, train=True, transform=transforms.ToTensor())\n",
    "valid_data = datasets.FashionMNIST(root='.', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2653c33f0d0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data[90][0].view(28, 28, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for RGB images we should calculate mean and std for each channel\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "all_num_pixcels_train = len(train_data) * 28 * 28\n",
    "\n",
    "total_sum_train = 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    total_sum_train += batch[0].sum()\n",
    "\n",
    "train_mean = total_sum_train / all_num_pixcels_train\n",
    "\n",
    "sum_of_squared_errot_train = 0\n",
    "\n",
    "for batch in train_loader:\n",
    "    sum_of_squared_errot_train += ((batch[0] - train_mean).pow(2)).sum()\n",
    "\n",
    "train_std = torch.sqrt(sum_of_squared_errot_train / all_num_pixcels_train)\n",
    "\n",
    "train_mean, train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2868), tensor(0.3524))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_loader = DataLoader(dataset=valid_data, batch_size=32, shuffle=True)\n",
    "all_num_pixcels_valid = len(valid_data) * 28 * 28\n",
    "\n",
    "total_sum_valid = 0\n",
    "\n",
    "for batch in valid_loader:\n",
    "    total_sum_valid += batch[0].sum()\n",
    "\n",
    "valid_mean = total_sum_valid / all_num_pixcels_valid\n",
    "\n",
    "sum_of_squared_errot_valid = 0\n",
    "\n",
    "for batch in valid_loader:\n",
    "    sum_of_squared_errot_valid += ((batch[0] - valid_mean).pow(2)).sum()\n",
    "\n",
    "valid_std = torch.sqrt(sum_of_squared_errot_valid / all_num_pixcels_valid)\n",
    "\n",
    "valid_mean, valid_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                    transforms.RandomCrop(size=(224, 224)),\n",
    "                                    transforms.RandomRotation(degrees=30),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=train_mean, std=train_std)\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                     transforms.CenterCrop(size=(224, 224)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(mean=valid_mean, std=valid_std)\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented = datasets.FashionMNIST(root='.', download=True, train=True, transform=train_transform)\n",
    "valid_data_augmented = datasets.FashionMNIST(root='.', download=True, train=False, transform=valid_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_augmented_loder = DataLoader(dataset=train_data_augmented, batch_size=32, shuffle=True)\n",
    "valid_data_augmented_loder = DataLoader(dataset=valid_data_augmented, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\pytorch-course\\torchenv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\pytorch-course\\torchenv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 7, 7])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv1_weights = model.conv1.weight\n",
    "conv1_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 7, 7])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.conv1.weight = torch.nn.Parameter(conv1_weights.sum(dim=1, keepdim=True))\n",
    "model.conv1.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.in_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_in_features = model.fc.in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(in_features=fc_in_features, out_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_valid_data = len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy epoch0: 0.7910999655723572\n",
      "validation accuracy epoch1: 0.7756999731063843\n",
      "validation accuracy epoch2: 0.8039999604225159\n",
      "validation accuracy epoch3: 0.8100999593734741\n",
      "validation accuracy epoch4: 0.7953999638557434\n",
      "validation accuracy epoch5: 0.8082000017166138\n",
      "validation accuracy epoch6: 0.8169999718666077\n",
      "validation accuracy epoch7: 0.7989000082015991\n",
      "validation accuracy epoch8: 0.7910000085830688\n",
      "validation accuracy epoch9: 0.8096999526023865\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(0, epochs):\n",
    "    model.train()\n",
    "   \n",
    "    if epoch % 2 == 0:\n",
    "        chechpoint = {\n",
    "            'model_state' : model.state_dict(),\n",
    "            'optimizer_state' : optimizer.state_dict(),\n",
    "            'epoch' : epoch\n",
    "        }\n",
    "        torch.save(chechpoint, 'chckpnt.pth')\n",
    "\n",
    "    for x, y in train_data_augmented_loder:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        yhat = model(x)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            loss = criterion(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "\n",
    "    for x_val, y_val in valid_data_augmented_loder:\n",
    "        x_val = x_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "    \n",
    "        yhat_val = model(x_val)\n",
    "        _, label = torch.max(yhat_val, 1)\n",
    "        correct += (label==y_val).sum()\n",
    "\n",
    "    valid_acc = correct / num_valid_data\n",
    "    \n",
    "    print(f'validation accuracy epoch{epoch}: {valid_acc}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
