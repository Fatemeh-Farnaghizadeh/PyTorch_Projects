{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2, stride=1)\n",
    "        self.max1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0, stride=1)\n",
    "        self.max2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(400, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.out = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.conv1(x))\n",
    "        x = self.max1(x)\n",
    "        x = torch.sigmoid(self.conv2(x))\n",
    "        x = self.max2(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = torch.sigmoid(self.fc1(x)) \n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (max1): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (max2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (out): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LeNet()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LeNet(nn.Module):\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 6, kernel_size=5, padding=2, stride=1)\n",
    "#         self.max1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "#         self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0, stride=1)\n",
    "#         self.max2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "#         self.fc1 = nn.Linear(400, 120)\n",
    "#         self.fc2 = nn.Linear(120, 84)\n",
    "#         self.out = nn.Linear(84, 10)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = nn.Sigmoid()(self.conv1(x))\n",
    "#         x = self.max1(x)\n",
    "#         x = nn.Sigmoid()(self.conv2(x))\n",
    "#         x = self.max2(x)\n",
    "#         # x = torch.view(-1, 1)\n",
    "#         x = nn.Flatten()(x)\n",
    "#         x = nn.Sigmoid()(self.fc1(x)) \n",
    "#         x = nn.Sigmoid()(self.fc2(x))\n",
    "#         x = self.out(x)\n",
    "\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='.', download=True, train=True, transform=transforms.ToTensor())\n",
    "valid_data = datasets.MNIST(root='.', download=True, train=False, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_data, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(dataset=valid_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 25\n",
    "num_train_data = len(train_data)\n",
    "num_valid_data = len(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_acc epoch: 0: 0.7311333417892456\n",
      "valid_acc epoch: 0: 0.9228999614715576\n",
      "train_acc epoch: 1: 0.9394500255584717\n",
      "valid_acc epoch: 1: 0.953499972820282\n",
      "train_acc epoch: 2: 0.9601666927337646\n",
      "valid_acc epoch: 2: 0.9705999493598938\n",
      "train_acc epoch: 3: 0.9714833498001099\n",
      "valid_acc epoch: 3: 0.9713999629020691\n",
      "train_acc epoch: 4: 0.9763000011444092\n",
      "valid_acc epoch: 4: 0.979699969291687\n",
      "train_acc epoch: 5: 0.9798166751861572\n",
      "valid_acc epoch: 5: 0.9812999963760376\n",
      "train_acc epoch: 6: 0.9828166961669922\n",
      "valid_acc epoch: 6: 0.9840999841690063\n",
      "train_acc epoch: 7: 0.9851666688919067\n",
      "valid_acc epoch: 7: 0.983299970626831\n",
      "train_acc epoch: 8: 0.9866333603858948\n",
      "valid_acc epoch: 8: 0.9846999645233154\n",
      "train_acc epoch: 9: 0.9881666898727417\n",
      "valid_acc epoch: 9: 0.9835000038146973\n",
      "train_acc epoch: 10: 0.9891499876976013\n",
      "valid_acc epoch: 10: 0.9854999780654907\n",
      "train_acc epoch: 11: 0.9901000261306763\n",
      "valid_acc epoch: 11: 0.9850999712944031\n",
      "train_acc epoch: 12: 0.990766704082489\n",
      "valid_acc epoch: 12: 0.9868999719619751\n",
      "train_acc epoch: 13: 0.9916999936103821\n",
      "valid_acc epoch: 13: 0.9853000044822693\n",
      "train_acc epoch: 14: 0.9923499822616577\n",
      "valid_acc epoch: 14: 0.986299991607666\n",
      "train_acc epoch: 15: 0.992566704750061\n",
      "valid_acc epoch: 15: 0.9864999651908875\n",
      "train_acc epoch: 16: 0.9935833215713501\n",
      "valid_acc epoch: 16: 0.9865999817848206\n",
      "train_acc epoch: 17: 0.9941999912261963\n",
      "valid_acc epoch: 17: 0.9875999689102173\n",
      "train_acc epoch: 18: 0.9947167038917542\n",
      "valid_acc epoch: 18: 0.9870999455451965\n",
      "train_acc epoch: 19: 0.9953666925430298\n",
      "valid_acc epoch: 19: 0.988599956035614\n",
      "train_acc epoch: 20: 0.9955166578292847\n",
      "valid_acc epoch: 20: 0.9874999523162842\n",
      "train_acc epoch: 21: 0.9953833222389221\n",
      "valid_acc epoch: 21: 0.98499995470047\n",
      "train_acc epoch: 22: 0.9960333704948425\n",
      "valid_acc epoch: 22: 0.9861999750137329\n",
      "train_acc epoch: 23: 0.9965000152587891\n",
      "valid_acc epoch: 23: 0.9837999939918518\n",
      "train_acc epoch: 24: 0.9965333342552185\n",
      "valid_acc epoch: 24: 0.9874999523162842\n"
     ]
    }
   ],
   "source": [
    "for epoch in range (0, epochs):\n",
    "    model.train()\n",
    "\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint = {\n",
    "            'model_state' : model.state_dict(),\n",
    "            'optim_state' : optimizer.state_dict(),\n",
    "            'epoch' : epoch\n",
    "        }\n",
    "\n",
    "    torch.save(checkpoint, 'chechpoint.pth')\n",
    "\n",
    "    correct_train = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "       \n",
    "        yhat = model(x)\n",
    "        _, train_label = torch.max(yhat, 1)\n",
    "\n",
    "        correct_train += (train_label == y).sum()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            loss = criterion(yhat, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "\n",
    "    train_acc = correct_train / num_train_data\n",
    "    \n",
    "    print(f'train_acc epoch: {epoch}: {train_acc}')\n",
    "\n",
    "    model.eval()\n",
    "    correct_valid = 0\n",
    "\n",
    "    for x_val, y_val in valid_loader:\n",
    "        x_val = x_val.to(device)\n",
    "        y_val = y_val.to(device)\n",
    "        \n",
    "        yhat_val = model(x_val)\n",
    "        _, yhat_label = torch.max(yhat_val, 1)\n",
    "        \n",
    "        correct_valid += (yhat_label == y_val).sum()\n",
    "\n",
    "    valid_acc = correct_valid / num_valid_data\n",
    "\n",
    "    print(f'valid_acc epoch: {epoch}: {valid_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f9c6aaa002d3192f42ad1ee0baf7c4d5cb257e2ada65ed9217998a4bb381b4e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
